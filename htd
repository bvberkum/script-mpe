#!/bin/sh
#
# Htdocs: work in progress 'daily' shell scripts
#
# Id: script.mpe/0.0.0+20150911-0659 htd

htd_src=$_
test -z "$__load_lib" || set -- "load-ext"

scriptdir="$(cd "$(dirname "$0")"; pwd -P)"

set -e

version=0.0.0+20150911-0659 # script.mpe


htd_load()
{
  # -- htd box load insert sentinel --
  test -n "$UCONFDIR" || UCONFDIR=$HOME/.conf/
  [ -n "$HTDIR" ] || HTDIR=$HOME/public_html
  [ -n "$CWDIR" ] || CWDIR=
  [ -n "$EDITOR" ] || EDITOR=vim
  [ -n "$HTD_GIT_REMOTE" ] || HTD_GIT_REMOTE=default
  # TODO look in registry for PROJECT
  [ -n "$PROJECT" ] || PROJECT="$(basename $(pwd))"
  _14MB=14680064
  _6MB=7397376
  _5k=5120
  test -n "$MIN_SIZE" || MIN_SIZE=$_6MB

  TODAY=+%y%m%d0000
  _1HR_AGO=+%y%m%d0000
  _15MIN_AGO=+%y%m%d0000
  _5MIN_AGO=+%y%m%d0000

  test -n "$hostname" || hostname="$(hostname -s | tr 'A-Z' 'a-z')"
  test -n "$uname" || uname="$(uname -s)"

  cwd=$(pwd)
  test "$cwd" = "$(pwd -P)" || warn "current path seems to be aliased"

  test -e table.sha1 && R_C_SHA3="$(cat table.sha1|wc -l)"

  stdio_type 0
  test "$stdio_0_type" = "t" && {
    rows=$(stty size|awk '{print $1}')
    cols=$(stty size|awk '{print $2}')
  } || {
    rows=32
    cols=79
  }

  htd_rules=~/.conf/rules/$hostname.tab
  ns_tab=$HOME/.conf/namespace/$hostname.tab

  HTD_IGNORE=.htdignore
  htd_init_ignores
  #match_load_table vars

  which tmux 1>/dev/null || {
    export PATH=/usr/local/bin:$PATH
  }

  which rst2xml 1>/dev/null && rst2xml=$(which rst2xml) \
    || { which rst2xml.py 1>/dev/null && rst2xml=$(which rst2xml.py) \
    || warn "No rst2xml"; }
}

htd_usage()
{
  echo "$scriptname.sh Bash/Shell script helper"
  echo 'Usage: '
  echo "  $scriptname <cmd> [<args>..]"
}

htd_commands()
{
  echo 'Commands: '
  echo '  home                             Print htd dir.'
  echo '  info                             Print vars.'
  echo '  mk|make                          Run make (in htd dir).'
  echo '  st|stat                          Run make stat.'
  echo '  sys                              Run make sys.'
  echo '  vt|vtoday                        Run make vtoday.'
  echo '  today [<prefix> [<ext>]]         Create symlinks of the format $PREFIX/{today,tomorrow,yesterday}.rst -> %Y-%m-%d.rst'
  echo ''
  echo 'Virtuals: '
  echo '  vbox-start <name>                Start headless VBoxVM for VM UUID with name in VBoxVM table. '
  echo '  vbox-suspend <name>              Suspend VBoxVM. '
  echo '  vbox-reset <name>                Reboot VBoxVM. '
  echo '  vbox-stop <name>                 Stop VBoxVM. '
  echo '  vbox-list                        List known and unknown VMs. '
  echo '  vbox-running                     List running VMs. '
  echo '  vbox-info [<name>]'
  echo ''
  echo '  lists [opts]                     List all lists. '
  echo '  tasks [<list>..]                 List tasks in lists'
  echo '  new-task <list> <title>          Add task to list with title'
  echo '  task-note <list> <num>           Edit notes of task in the $EDITOR'
  echo '  task-title <list> <num> [<title>]'
  echo '                                   Get or update title of task'
  echo '  done <list> <num>                Toggle task completed status'
  echo '  todo                             '
  echo ''
  echo 'Networking'
  echo '  wol <host>                       Send wol to mac for host from WOL table.'
  echo '  mac                              List ARP table: hwaddr for clients (once) connector to LAN. '
  echo ''
  echo 'File Versioning'
  echo '  git-remote [repo]                List all names remotely, or give the SSH url for given repo. '
  echo '  git-init-remote [repo]           Initialze remote bare repo if local path is GIT project'
  echo '  git-remote-info                  Show current ~/.conf/git-remotes/* vars.'
  echo '  git-largest-objects (10)         List the SHA1 sums of the largest objects.'
  echo '  git-path-for-object <sha1>       Given SHA1 object, find its current path.'
  echo '  git-annex-unused                 Show keys of stored objects without path using them. '
  echo '  git-annex-show-unused            Show commit logs for unused keys. '
  echo '  git-annex-clear-unused [<to>]    Drop the unused keys, or move to remote. '
  echo ''
  echo 'Working tree utils'
  echo '  check-names [. [<tags>]]         Check names in path, according to tags.'
  echo '  list-paths [.|<dirpath]          List all paths below, including dirs. '
  echo '  test-name <path>                 Test filename for unhandled characters. '
  echo '  find-name <path|localname>       TODO: Given (partial) path, try to find the file using find.  '
  echo '  update                           Fill checksums tables for all local files. TODO: find out what there is to know about file using settings, other commands, ext. tooling & services. And trigger resolve'
  echo '  '
  echo 'Rules'
  echo '  resolve                          XXX based on data and settings, pre-process and mark all files ready for commit, and bail on any irregularities. '
  echo '  commit                           XXX record metadata according to htd settings/commands. Commit is only a success, if the entire tree is either clean or ignored. '
  echo '  show-rules [<path>]              tabulate all rules that would apply to path'
    echo '  run-rules [<path>]               (re-)run rules on path'
  echo '  add-rule <pattern> <functions>|<script> '
  echo '                                   Add either function and inline script to run for every path matching pattern. '
  echo ''
  echo 'Working tree metadata'
  echo '  ck-consolidate [.|<path>]        TODO: integrate metadata from all metafiles (see ck-metafile)'
  echo '  ck-metafile <path>               TODO: integrate metadata from .meta/.rst/.sha1sum/etc. '
  echo ''
  echo 'Working tree checksum metadata [CK_TABLE=./]'
  echo '  ck-update [ck|md5|sha1] (<path>)  Iterate all files, and create checksum table records for unknown files. '
  echo "  ck-table [ck|md5|sha1] <path>    Tell if checksum exists for file, don\'t validate or update. "
  echo '  ck-table-subtree [ck|md5|sha1] <path> '
  echo '                                   Like ck-table, but this takes a partial path starting at the root level and returns the checksum records for files below that. '
  echo '  ck-drop [ck|mk5|sha1] <path>     Remove row for given path from checksum table. '
  echo '  ck-validate [ck|md5|sha1]        Verify each file by generating and comparing its checksum. '
  echo '  ck-check [ck|md5|sha1]           Iterate table, move lines with non-existant paths to .missing table'
  echo '  ck-fix [.|<path>]                If path exists, look for duplicates using ck-find-content and move this path to .duplicates marking it to be resolved interactively. '
  echo '                                   Or if path is missing, try find-name to find new location. If still missing, look for any copy using ck-find-content and move current entry to table .duplicate on success, or .gone on failure. '
  echo '  ck-check-missing [ck|md5|sha1]   TODO: iterate .missing table, and call ck-fix. Move checksum to .gone if file stays missing. '
  echo '  ck-clean [ck|md5|sha1]           TODO: iterate .gone table, and call ck-fix. Move gone checksum if file stays missing. '
  echo '  ck-purge [|missing|duplicate|gone] TODO: drop missing-paths from indicate tables. '
  echo '  ck-dedup <path>                  With no path given, iterate the duplicate table. Otherwise deduplicate content, using given path as preferred location. '
  echo '  ck-find-content <path>           Given path, try find-name or checksum tables and annex-backend to find copies and give all alternate locations. '
  echo ''
  echo 'Other commands: '
  other_cmds
}
other_cmds()
{
  echo '  -E|edit-main                     Edit this script.'
  echo '  -e|edit                          Edit a local document or script.'
  echo '  alias                            Show bash aliases for this script.'
  echo '  -h|help                          Give a combined usage, command and docs. '
  echo '  docs                             Echo manual page. '
  echo '  commands                         Echo this comand description listing.'
  echo "  usage                            List all commands. "
  echo "  info                             List env info. "
  echo "  files                            List file used by htd. "
  echo '  mk|make                          Run make (in htd dir).'
  echo '  vt|vtoday                        Run make vtoday.'
}

htd__docs()
{
  echo "Docs:" 
  echo ""
}

htd__files()
{
  echo "Files"
  echo ""
  echo "    From config settings:"
  echo "  $vbox_names (\$vbox_names)"
  echo "  $wol_hwaddr (\$wol_hwaddr)"
  echo ""
  echo "    From CWD:"
  echo "  ./TODO.list"
  echo "  ./table.names"
  echo "  ./invalid.paths"
  echo "    TODO: uses path .git/.."
  echo "    TODO: paths used by matchbox"
  echo ""
  echo "    Temporary left after exec:"
  echo "  /tmp/gtasks-\$list-\$num-note"
  echo ""
  echo "    Config files"
  echo "  ~/.conf/git-remotes/\$HTD_GIT_REMOTE.sh"
  echo "  ~/.conf/rules/\$host.sh"
  echo ''
  echo 'See dckr for container commands and vc for GIT related. '
}

htd_man_1__commands="List all commands"
htd__commands()
{
  choice_global= choice_all=true std_commands
}


htd_man_1__help="Echo a combined usage, command and docs"
htd__spc_help="-h|help [<id>]"
htd__help()
{
  test -z "$1" && {
    htd_usage
    echo ''
    echo 'Main commands: '
    other_cmds
  } || {
    echo_help $1
  }
}
htd_als___h=help


htd_man_1__version="Version info"
htd__version()
{
  echo "$(cat $LIB/.app-id)/$version"
}
htd_als___V=version


htd__home()
{
  echo $HTDIR
}

htd__info()
{
  echo "env"
  echo "  CWDIR"
  echo "    If set, use instead of the current directory for working dir. "
  echo ""
  log "Script:                '$(pwd)/$scriptname'"
  log "User Config Dir:       '$UCONFDIR' [UCONFDIR]"
  log "User Public HTML Dir:  '$HTDIR' [HTDIR]"
  log "Current workingdir:    '$CWDIR' [CWDIR]"
  log "Project ID:            '$PROJECT' [PROJECT]"
  log "Minimum filesize:      '$(( $MIN_SIZE / 1024 ))'"
  log "Editor:                '$EDITOR' [EDITOR]"
  log "Default GIT remote:    '$HTD_GIT_REMOTE' [HTD_GIT_REMOTE]"
  log "Ignored paths:         '$HTD_IGNORE' [HTD_IGNORE]"
}

htd__expand()
{
  test -n "$1" || return 1
  for x in $1
  do
    test -e "$x" && echo $x
  done
}


htd_man_1__edit_main="Edit the main script file"
htd__spc_edit_main="-E|edit-main"
htd__edit_main()
{
  locate_name
  [ -n "$fn" ] || error "expected $scriptname?" 1
  $EDITOR $fn "$@"
}
htd_als___E=edit-main


htd_man_1__edit="Edit a local file, or abort"
htd__spc_edit="-e|edit <id>"
htd__edit()
{
  test -n "$1" || error "search term expected" 1
  doc_path_args
  find_paths="$(doc_find_name "$1")"
  grep_paths="$(doc_grep_content "$1")"
  test -n "$find_paths" -o -n "$grep_paths" \
    || error "Nothing found to edit" 1
  $EDITOR $find_paths $grep_paths
}
htd_als___e=edit


htd_man_1__count="Look for doc"
htd__spc_count="count"
htd__count()
{
  doc_path_args

  info "Counting files with matching name '$1' ($paths)"
  doc_find_name "$1" | wc -l

  info "Counting matched content '$1' ($paths)"
  doc_grep_content "$1" | wc -l
}

htd_man_1__find="Look for document. "
htd__spc_find="-f|find (<path>|<localname> [<project>])"
htd__find()
{
  doc_path_args

  info "Searching files with matching name '$1' ($paths)"
  doc_find_name "$1"

  info "Searching matched content '$1' ($paths)"
  doc_grep_content "\<$1\>"
}
htd_als___f=find



htd__man_5__htdignore_merged='Exclude rules used by `htd find|edit|count`, compiled from other sources using ``htd init-ignores``. '

htd_man_1__init_ignores="Write all exclude rules to .htdignores.merged"
htd__init_ignores()
{
  htd_init_ignores
}


htd_man_1__relative_path="Test for relative path"
htd__relative_path()
{
  # TODO: maybe build relative path from 1 arg and cwd, or two args
  # see also mkrlink. Also clean up.
  #x_re "${1:0:2}" '[\.\/]*' && echo ok || echo nok
  htd_relative_path $1
  r=$?
  echo relpath=$relpath
  exit $r
}
htd_man_1__relpath="Alias for 'relative-path'"
htd_als__relpath='relative-path'


# XXX: add config files
htd__man_5_table_names=""

htd__test_find_path_locals()
{
    htd_find_path_locals table.names $1
    echo path_locals=$path_locals

    htd_find_path_locals table.names $1 $(pwd)
    echo path_locals=$path_locals
}

# List root IDs
htd__list_local_ns()
{
  fixed_table_hd $ns_tab ID PATH CMD | while read vars
  do
    eval local "$vars"
    echo $ID
  done
}

# XXX: List matching tags
htd__spc_ns_names='[<path>|<localname> [<ns>]]'
htd__ns_names()
{
  test -z "$3" || error "Surplus arguments: $3" 1
  fixed_table_hd $ns_tab ID CMD_PATH CMD | while read vars
  do
    eval local "$vars"
    test -n "$2" && {
      echo 2=$2
      test "$2" = "$ID" || continue
    }
    cd $CMD_PATH
    note "In '$ID' ($CMD_PATH)"
    eval $CMD "$1"
    cd $cwd
  done
}

# TODO: List resources containing tag
htd__ns_resources()
{
  set --
}


htd__fsck()
{
  htd__ck_validate sha1
}

htd__make()
{
  cd $HTDIR && make $*
}
htd__mk()
{
  htd__make $*
}

# Run a sys-* target in the main htdocs dir.
htd__make_sys()
{
  cd $HTDIR
  for x in $*
  do
    make system-$x
  done
}

htd__stat()
{
  htd__make stat
}

htd_als__st=stat
htd__st()
{
  cmd=stat htd__stat $*
}

htd__build()
{
  rm -f /tmp/htd-out
  htd__make build 2>1 | capture_and_clear
  echo Mixed output::
  echo
  cat /tmp/htd-out | sed  's/^/    /'
}

# show htd shell aliases
htd__alias()
{
  grep '\<'$scriptname'\>' ~/.alias | grep -Ev '^(#.*|\s*)$' | while read _a A
  do
    a_id=$(echo $A | awk -F '=' '{print $1}')
    a_shell=$(echo $A | awk -F '=' '{print $2}')
    echo -e "   $a_id     \t$a_shell"
  done
}

# Open an editor to edit todays log
htd__vtoday()
{
  ht__today personal/journal
  $EDITOR personal/journal/{today,tomorrow,yesterday}.rst
  git add personal/journal/
}
htd_als__vt=vtoday


# update yesterday, today and tomorrow links
htd__today()
{
  test -z "$1" && P=journal || P=$1
  test -d "$P" || error "Dir $(pwd)/$P must exist" 1
  YSEP=/
  Y=%Y
  MSEP=-
  M=%m
  DSEP=-
  D=%d
  test -z "$EXT" && EXT=.rst || EXT=$EXT
  r=$P$YSEP
  p=$P$YSEP$Y$MSEP$M$DSEP$D$EXT
  datelink -1d "$p" ${r}yesterday$EXT
  datelink "" "$p" ${r}today$EXT
  datelink +1d "$p" ${r}tomorrow$EXT
  for tag in sunday monday tuesday wednesday thursday friday saturday
  do
    datelink "$tag -7d" "$p" "${r}last-$tag$EXT"
    datelink "$tag +7d" "$p" "${r}next-$tag$EXT"
    datelink "$tag" "$p" "${r}$tag$EXT"
  done
}


### VirtualBox

vbox_names=~/.conf/vbox/vms.sh
htd__vbox()
{
  name=$1
  [ -z "$name" ] && {
    htd__vbox_list
  } || {
    declare $(echo $(cat $vbox_names))
    uuid=$(eval echo \$$name)
    test -n "$uuid" || error "No such vbox VM '$name'" 1
  }
}

htd__vbox_start()
{
  test -n "$1" || error "VM name required" 1
  htd__vbox $1
  VBoxManage startvm ${uuid} --type headless \
      || error "Headless-start of VM $name" 1 \
      && log "Headless-start of VM $name completed successfully"
}

htd__vbox_start_console()
{
  test -n "$1" || error "VM name required" 1
  htd__vbox $1
  VBoxManage startvm ${uuid} \
      || error "Console-start of VM $name" 1 \
      && log "Console-start of VM $name completed successfully"
}

htd__vbox_reset()
{
  test -n "$1" || error "VM name required" 1
  htd__vbox $1
  VBoxManage controlvm ${uuid} reset \
      || error "Reset of VM $name" 1 \
      && log "Reset of VM $name completed successfully"
}

htd__vbox_stop()
{
  test -n "$1" || error "VM name required" 1
  htd__vbox $1
  VBoxManage controlvm ${uuid} poweroff \
      || error "Power-off of VM $name" 1 \
      && log "Power-off of VM $name completed successfully"
}

htd__vbox_suspend()
{
  test -n "$1" || error "VM name required" 1
  htd__vbox $1
  VBoxManage controlvm ${uuid} savestate \
      || error "Save-state of VM $name" 1 \
      && log "Save-state of VM $name completed successfully"
}

htd__vbox_list()
{
  VBoxManage list vms | \
    sed 's/^"\(.*\)"\ {\(.*\)}$/\2 \1/' | while read uuid name
  do
    grep $uuid $vbox_names >> /dev/null || echo unknown $name =$uuid
  done
  cat $vbox_names | \
    grep -Ev '^\s*(#.*|\s*)$'
}

htd__vbox_running()
{
  VBoxManage list runningvms
}

htd__vbox_info()
{
  test -n "$1" && {
    htd__vbox $1
    #2: --details --machinereadable
    VBoxManage showvminfo ${uuid} $2
  } || {
      for sub in intnets bridgedifs hostonlyifs natnets dhcpservers
      do log "Showing $sub"; VBoxManage list $sub; done
  }
}

htd__vbox_gp()
{
  htd__vbox "$1"
  VBoxManage guestproperty enumerate ${uuid}
  #VBoxManage guestproperty get ${uuid} "/VirtualBox/GuestInfo/Net/0/V4/IP"
}


# Wake a remote host using its ethernet address
wol_hwaddr=~/.conf/wol/hosts-hwaddr.sh
htd__wol_list_hosts()
{
  cat $wol_hwaddr
  error "Expected hostname argument" 2
}
htd__wake()
{
  host=$1
  [ -z "$host" ] && {
    htd__wol_list_hosts
  } || {
    declare $(echo $(cat $wol_hwaddr))
    hwaddr=$(eval echo \$$host)
    [ -n "$hwaddr" ] || exit 4
    wakeonlan $hwaddr
    echo ":WOL Host: \`$host <$hwaddr>\`_"
  }
}

# Simply list ARP-table, may want something better like arp-scan or an nmap
# script
htd__mac()
{
  arp -a
}

# 

htd__cron()
{
  printf ""
}

htd__project()
{
  printf ""
}

htd__project_todo()
{
  title=
  descr=
  refs=
}

# Experimenting with gtasks.. looking at todo targets
htd__todo()
{
  test -e TODO.list && {
    cat TODO.list | \
      grep -Ev '^(#.*|\s*)$' | \
      while read line
      do
        todo_read_line "$line"
        todo_clean_descr "$comment"
        echo "$fn $ln  $tag  $descr"
        # (.,.)p
      done
  } || {
    echo
    echo "..Htdocs ToDo.."
    gtasks -L -dsc -dse -sn
    echo "Due:"
    gtasks -L -sdo -dse -sn
#  echo ""
#  gtasks -L -sb tomorrow -sa today -dse
  }
}

todo_clean_descr()
{
  echo "$@" | \
  grep -E '^.*(TODO|XXX|FIXME)[\ \:]*(.*)((\?\ )|(\.\ )|(\.\s*$)).*$' \
  > /dev/null && {
    clean=$( echo "$@" | \
      sed -E 's/^.*(TODO|XXX|FIXME)[\ \:]*(.*)((\?\ )|(\.\ )|(\.\s*$)).*$/\1 \2\3/' )
  } || {
    clean=$( echo "$@" | \
      sed -E 's/^.*(TODO|XXX|FIXME)[\ \:]*(.*)$/\1 \2/' )
  }
  tag=$(echo $clean|cut -f 1 -d ' ')
  descr="$(echo ${clean:$(( ${#tag} + 1 ))})"
  test -n "$descr" -a "$descr" != " " && {
    echo $descr | grep -E '(\.|\?)$' > /dev/null || {
      set --
      # TODO: scan lines for end...
    }
  }
}

todo_read_line()
{
  line="$1"
  fn=$(echo $line | cut -f 1 -d ':')
  ln=$(echo $line | cut -f 2 -d ':')
  test "$ln" -eq "$ln" 2> /dev/null \
    || error "Please include line-numbers in the TODO.list" 1
  comment=${line:$((  ${#fn} + ${#ln} + 2  ))}
}


htd_grep_line_exclude()
{
  grep -v '.*\ htd:ignore\s*'
  # TODO: build lookup util for ignored file line ranges
  #| while read line
  #do
  #    file=$()
  #    linenr=$()
  #    htd__htd_excluded_line $file $linenr
  #done
}

htd_man_1__build_todo_list="Build indented file of path/line/tag from FIXME: etc tagged
src files"
htd__build_todo_list()
{
  test -n "$1" || set -- TODO.list "$2"
  test -n "$2" || {
    test -s .app-id \
        && set -- "$1" "$(cat .app-id)" \
        || set -- "$2" "$(basename $(pwd))"
  }

  { for tag in FIXME TODO NOTE XXX
  do
    grep -nsrI $tag':' . \
        | grep -v $1':' \
        | htd_grep_line_exclude \
        | while read line;
      do
        tid="$(echo $line | sed -n 's/.*'$tag':\([a-z0-9\.\+_-]*\):.*/\1/p')"
        test -z "$tid" \
            && echo "$(pwd);$2#$tag;$line" \
            || echo "$(pwd);$2#$tag:$tid;$line";

      done
  done; } | todo-meta.py import -

#  grep -nsrI '\(\<FIXME\|TODO\|NOTE\|XXX\>\):' . \
#      | grep -v '^#|\s*$' \
#      | grep -v '.*#\ htd:ignore\s*' \
#      | sort \
#      | sed 's/\:\([0-9]*\)\:[\s\#]*/:\
#\ \ \1\
#\ \ \ \ /g' > $1
}


# Lists and tasks

gtasks_list_arg()
{
    test -z "$1" && list=Standaardlijst || list="$1"
}
gtasks_num_arg()
{
    test -z "$1" && return 1 || num="$1"
}
gtasks_list_opt()
{
  test -z "$1" && {
    list="-l Standaardlijst"
  } || {
    test "${1:0:1}" = "-" && {
      # possibly use verbatim opts (-L)
      list="$1"
    } || {
      list="-l $1"
    }
  }
}
gtasks_opts()
{
  cnt=0
  gtasks_opts=
  while test "${1:0:1}" = "-"
  do
    gtasks_opts="$gtasks_opts $1"
    cnt=$(( $cnt + 1 ))
    shift 1
  done
  return $cnt
}

htd_file_arg()
{
  test -n "$1" && {
    file=$1
    shift 1
  } || return 1
}

# List all lists
htd__lists()
{
  test -n "$gtasks_opts" || gtasks_opts="-dsc"
  gtasks -ll $gtasks_opts
}

# List tasks in lists
htd__tasks()
{
  gtasks_opts $@
  shift $?
  test -n "$gtasks_opts" || gtasks_opts="-dsc"
  test -z "$1" && {
    gtasks_list_opt
    gtasks $list $gtasks_opts
  }
  while test -n "$1"
  do
    gtasks_list_opt $@ && shift 1
    gtasks $list $gtasks_opts
  done
}

# Add task to list with title
htd__new_task()
{
  gtasks_list_arg $1 && shift 1
  gtasks -l "$list" -a - -t "$@"
}

# Edit notes of a task in the $EDITOR
htd__task_note()
{
  gtasks_list_arg $1 && shift 1
  gtasks_num_arg $1 && shift 1 || exit 1
  tmpf=/tmp/gtasks-$list-$num-note
  title="$(gtasks -dsc -l "$list" -gt $num)"
  mkdir -p $(dirname $tmpf)
  gtasks -dsc -l "$list" -gn $num > $tmpf.current
  check_pre=$(md5sum $tmpf.current | cut -f 1 -d ' ')
  echo -e "$title\n" > $tmpf.txt
  cat $tmpf.current >> $tmpf.txt
  $EDITOR $tmpf.txt
  new_title=$(head -n 1 $tmpf.txt)
  tail -n +3 $tmpf.txt > $tmpf.new
  check=$(md5sum $tmpf.new | cut -f 1 -d ' ')
  test "$title" != "$new_title" && {
    printf "Updating title ... "
    gtasks -l "$list" -e $num -t "$new_title" -dsl
  } || {
    echo "No changes to title. "
  }
  test "$check_pre" != "$check" && {
    printf "Updating notes ... "
    gtasks -l "$list" -e $num -n "$(cat $tmpf.new)" -dsl
  } || {
    echo "No changes to notes. "
  }
}

# Get or updte title of task
htd__task_title()
{
  gtasks_list_arg $1 && shift 1
  gtasks_num_arg $1 && shift 1 || exit 1
  test -z "$1" && {
    gtasks -dsc -l "$list" -gt $num
  } || {
    gtasks -dsc -l "$list" -e $num -t "$1"
  }
}

# Toggle task completed status
htd__done()
{
  test -n "$2" && {
    test "$2" -gt 0 && {
      gtasks_list_arg $1 && shift 1
      gtasks_num_arg $1 && shift 1 || exit 1
    }
  } || {
    test -n "$1" -a "$1" -gt 0 && {
      # default list
      gtasks_list_arg
      gtasks_num_arg $1 && shift 1 || exit 1
    }
  }
  gtasks -dsc -l "$list" -c $num
}

# TODO: get references from file
htd__urls()
{
  htd_file_arg $1 || exit 1
  shift 1
  grep '\([a-z]\+\):\/\/.*' $file | while read url
  do
    sha1=$(printf $url | sha1sum - | cut -d ' ' -f 1)
    md5=$(printf $url | md5sum - | cut -d ' ' -f 1)
    echo $sha1 $md5 $url
  done
}

# init or list SSH based remote 

source_git_remote()
{
  test -n "$1" || set -- "$HTD_GIT_REMOTE"
  . ~/.conf/git-remotes/$1.sh \
      || error "Missing 1=$1 script" 1
}

htd__git_remote_info()
{
  test -n "$1" || set -- "$HTD_GIT_REMOTE"
  source_git_remote "$1"
  echo remote.$1.dir=$remote_dir
  echo remote.$1.host=$remote_host
  echo remote.$1.user=$remote_user
}
htd__git_remote()
{
  test -n "$2" && {
    source_git_remote $1; shift 1
  } || source_git_remote

  [ -z "$1" ] && {
    ssh_cmd="cd $remote_dir; ls | grep '.*.git$' | sed 's/\.git$//g' "
    ssh $ssh_opts $remote_user@$remote_host "$ssh_cmd"
  } || {
    repo=$1
    #git_url="ssh://$remote_host/~$remote_user/$remote_dir/$repo.git"
    scp_url="$remote_user@$remote_host:$remote_dir/$repo.git"
    echo $scp_url
  }
}

htd__git_init_remote()
{
  source_git_remote
  [ -n "$1" ] && repo="$1" || repo="$PROJECT"

  ssh_cmd="mkdir -v $remote_dir/$repo.git"
  ssh $remote_user@$remote_host "$ssh_cmd"

  [ -e .git ] || error "No .git directory, stopping remote init" 0

  htd__git_remote $repo >> /dev/null

  BARE=../$repo.git
  TMP_BARE=1
  [ -d $BARE ] && TMP_BARE= || {
    [ -d /src/$repo.git ] && {
      TMP_BARE=
      BARE=/src/$repo.git
    } || {
      log "Creating temp. bare clone"
      git clone --bare . $BARE
    }
  }

  [ -n "$TMP_BARE" ] || {
    log "Using existing bare repository to init remote: $BARE"
  }

  log "Syning new bare repo to $scp_url"
  rsync -azu $BARE/ $scp_url
  [ -n "$TMP_BARE" ] && {
    log "Deleting temp. bare clone ($BARE)"
    rm -rf $BARE
  }

  log "Adding new remote, and fetching remote refs"
  git remote add $HTD_GIT_REMOTE $scp_url
  git fetch $HTD_GIT_REMOTE

  log "Added remote $HTD_GIT_REMOTE $scp_url"
}

htd__git_drop_remote()
{
  [ -n "$1" ] && repo="$1" || repo="$PROJECT"
  log "Checking if repo exists.."
  ssh_opts=-q
  htd__git_remote | grep $repo || {
    error "No such remote repo $repo" 1
  }
  source_git_remote
  log "Deleting remote repo $remote_user@$remote_host:$remote_dir/$repo"
  ssh_cmd="rm -rf $remote_dir/$repo.git"
  ssh -q $remote_user@$remote_host "$ssh_cmd"
  log "OK, $repo no longer exists"
}



# indexing, cleaning

htd_name_precaution() {
  echo "$1" | grep -E '^[]\[{}\(\)A-Za-z0-9\.,!@#&%*?:'\''\+\ \/_-]*$' > /dev/null || return 1
}

htd__test_name()
{
  match_grep_pattern_test "$1" || return 1
  htd_name_precaution "$1" || return 1
  test "$cmd" = "test-name" && {
    echo 'name ok'
  }
  return 0
}

htd__find_empty()
{
  eval find . $find_ignores -o -size 0 -a -print
}

htd__filesize()
{
  filesize "$1"
}

# XXX: a function to clean directories
# TODO: hark back to statusdir?
# TODO: notice deprecation marks
htd__check()
{
  log "Looking for unknown files.."

  pwd=$(pwd)
  cruft=/tmp/htd-$(echo $pwd|tr '/' '-')-cruft.list
  test ! -e "$cruft" || rm $cruft
  eval find . $find_ignores -o -print \
    | while read p
    do

      htd__test_name "$p" >> /dev/null || {
        warn "Unhandled characters: $p"
        continue
      }

      [ -L "$p" ] && {
        BE="$(dirname "$p")/$(readlink "$p")"
        [ -e "$BE" ] || {
          warn "Skip dead symlink"
          continue
        }
        SZ="$(filesize "$BE")"
      } || {
        SZ="$(filesize "$p")"
      }

      if test -d "$p" -a -n "$(htd__expand $p.{zip,tar{.gz,.bz2}})"
      then
        info "Skipping unpacked dir $p"
        for ck in ck sha1 md5
        do
          htd__ck_table_subtree $ck "$p" | while read p2
          do
            htd__ck_table $ck "$p2" > /dev/null && {
              #htd__ck_drop $ck "$p"
              warn "FIXME: Dropped $ck key for $p"
            }
          done
        done
        continue
      fi

      test "$SZ" -ge "$MIN_SIZE" || {
        info "File too small: $p"
        echo $p >>$cruft
        continue
      }

    done

  test -s "$cruft" && {
    note "Cruft in $pwd: $(line_count $cruft) files"
  } || noop

}

htd_git_rename()
{
  $PREFIX/bin/matchbox.py rename "$1" "$2" |
  grep -Ev '^\s*(#.*|\s*)$' |
  while read file_old file_new
  do
    $cmd_pref git mv "$file_old" "$file_new"
  done
}

htd__rename_test()
{
  cmd_pref="echo"
  htd__rename $@
}

htd__rename()
{
  from_pattern="$1"
  to_pattern="$2"
  #$(echo $2 | sed 's/@\([A-Z0-9_]*\)/${\1}/g')
  shift 2
  test -z "$1" && {
    htd_git_rename "$from_pattern" "$to_pattern"
  } || {
    { for p in $@; do echo $p; done ; echo -e "\l"; } |
    htd_git_rename "$from_pattern" "$to_pattern"
  }
}

# List all paths including dirs
htd__list_paths()
{
  req_path_arg "$@"
  eval find $path $find_ignores -o -print
}

htd__check_names()
{
  test -z "$1" && d="." || { d="$1"; shift 1; }
  test -z "$1" && valid_tags="" || valid_tags="$1"
  test "${d: -1:1}" = "/" && d="${d:0: -1}"

  test -z "$valid_tags" &&
  log "Looking for unmatched paths in $d" ||
  log "Validating $d, using valid patterns $valid_tags"

  {
    eval find $d "$find_ignores -o \( -type l -o -type f \) -a -print "
    echo "\l"
  } | matchbox.py check-names $valid_tags
}

htd__fix_names()
{
  local path_regex names_tables names_table
  req_path_arg "$1"
  match_grep_pattern_test "$path" || return 1
  path_regex="$p_"
  match_name_tables "$path"
  # 
  htd_find_path_locals table.names $(pwd)
  names_tables=$path_locals
  for names_table in $names_tables
  do
    cat $names_table | grep -Ev '^(#.*|\s*)$' | while read match pattern tag
    do
      echo "$match" | grep '^'$path_regex > /dev/null || continue
      match_name_pattern "$pattern"
      for p in $match
      do
        echo "$p" | grep '^'"$grep_pattern"'$' >> /dev/null && {
          test -n "$tag" && {
            echo matched $tag $p
          } || {
            echo ok $p
          }
        } || test -n "$tag" || {
          echo mismatch $p
        }
      done
    done
  done
}

htd_host_arg()
{
  test -z "$1" && host=$1 || host=${hostname}
}

# TODO: pre-process file/metadata
htd__resolve()
{
  set --
}

# GIT commits and push
htd__pci()
{
  git add -u;git commit -m "$1";git push --all
}

# Move path to archive path in htdocs cabinet
# $ archive [<prefix>]/[<datepath>]/[<id>] <refs>...
htd__archive()
{
  test -n "$1" || error "ID expected"
}

## Annex:

# Save refs (download locators if not present) to prefix,
# building a full path for each ref from the prefix+ids+filetags.
# $ save "[<prefix>/]<id>" <refs>...
# TODO: define global <prefix> and <id> to correspond with (sets of) path instances
# ie. lookup given prefix and id first, see if it exists.
# XXX: may have lookup lookup. Use -g to override.
# <prefix> 
htd__save()
{
  htd__save_tags "$1"
  htd__save_url "$@"
}

htd__save_tags()
{
  set -- $@
  while test -n "$1"
  do
    tags.py get "$1" || tags.py insert "$1"
    shift 1
  done
}

htd__tags()
{
  test -n "$1" || set -- "*"
  tags.py find "$1"
}

htd__save_topics()
{
  test -n "$1" || error "Document expected" 1
  test -e "$1" || error "No such document $1" 1
  htd__tpaths "$1" | while read path
  do
    echo
  done
}


htd__save_url()
{
  annex=/Volumes/Simza/Downloads
  test "$(pwd -P)" = $annex || cd $annex

  test -n "$1" || error 'URL expected' 1
  test -n "$2" || {
    parseuri.py "$1"
    error "TODO: get filename"
  }
  test ! -e "$2" || error "File already exists: $2" 1
  git annex addurl "$1" --file "$2"
}

htd__save_ref()
{
  test -n "$1" || error "tags expected" 1
  tags="$1"
  
  shift 1
  for ref in "$@"
  do
    echo $ref
  done
}

htd__commit()
{
  echo -e
}

htd__show_rules()
{
  htd_host_arg
  cat $htd_rules
}


# htdoc rules development documentation in htdocs:Dev/Shell/Rules.rst
# pick up with config:rules/comp.json and build `htd comp` aggregate metadata
# and update statemachines.
htd__period_status_files()
{
  touch -t $(date +%y%m%d%H%M) $(statusdir.sh file period 1min)
  M=$(date +%M)
  _5M=$(( $(( $M / 5 )) * 5 ))
  touch -t $(date +%y%m%d%H${_5M}) $(statusdir.sh file period 5min)
  touch -t $(date +%y%m%d%H00) $(statusdir.sh file period hourly)
  H=$(date +%H)
  _3H=$(printf "%02d" $(( $(( $H / 3 )) * 3 )))
  touch -t $(date +%y%m%d${_3H}00) $(statusdir.sh file period 3hr)
  touch -t $(date +%y%m%d0000) $(statusdir.sh file period daily)
  ls -la $(statusdir.sh file period 3hr)
  ls -la $(statusdir.sh file period 5min)
  ls -la $(statusdir.sh file period hourly)
}

htd__run_rules()
{
  htd__period_status_files
  test -z "$DEBUG" \
    || fixed_table_hd_offsets $htd_rules CMD RT TARGETS CWD
  fixed_table_hd $htd_rules CMD RT TARGETS CWD | while read vars
  do
    eval local "$vars"
    #echo "CMD=$CMD RT=$RT TARGETS=$TARGETS"
    for target in $TARGETS
    do
      case "$target" in
        p:* )
            test -e "$(statusdir.sh file period ${target#*:})" && {
              echo "TODO 'cd $CWD;"$CMD"' for $target"
            } || error "Missing period for $target"
          ;;
        @* ) continue ;;
      esac
      # XXX: figuring out what/how rules to run
      htd__rule_target $target || note "TODO run '$CMD' for $target ($CWD)"
    done
  done
}

htd__edit_rules()
{
  $EDITOR $htd_rules $0
}

# arg: 1:target
# ret: 2: has run but failed or incomplete, 1: not run, 0: run was ok
htd__rule_target()
{
  case "$1" in

    # Period: assure exec once each period
    p:* )
      case "$1" in
        [smhdMY]* ) ;;
        [0-9]* )
          tdate=$(date +%y%m%d0000)
          ;;
      esac
      ;;

    # Domain
    d:* )
      sf=$(statusdir.sh file domain-network)
      test -e "$sf" || return 0
      test "d:$(cat $sf)" = "$1" || return 1
      ;;

    @* )
      sf=$(statusdir.sh file htd-rules-$1)
      test -s $sf && return 2 || test -e $sf || return 1
      ;;

  esac
}

htd__add_rule()
{
  set --
}

# parse path and annex metadata using given path

req_arg_pattern="Pattern format"
req_arg_path="Path"

htd__name_tags_test()
{
  match_name_vars $@
}

htd__name_tags()
{
  local pattern
  req_arg "$1" 'name-tags' 1 pattern && shift 1|| return 1
  req_arg "$1" 'name-tags' 2 path && path="$1" || return 1
  c=0
  test "${path: -1:1}" = "/" && path="${path:0: -1}"
  test -d "$path" && {
    eval find "$path $find_ignores -o \( -type f -o -type l \) -a -print" \
    | while read p
    do
      echo $p
      match_name_vars "$pattern" "$p" 2> /dev/null
      #c=$(( $c + 1 ))
      #echo $c
      #echo
    done
  } || {
    error "Req dir arg" 1
  }
}

htd__name_tags_all()
{
  req_arg "$1" 'name-tags-all' 1 path && path="$1" || return 1
  test "${path: -1:1}" = "/" && path="${path:0: -1}"
  test -d "$path" && {
    eval find "$path $find_ignores -o \( -type f -o -type l \) -a -print" \
    | while read p
    do
      match_names "$p"
    done
  } || {
    error "Req dir arg" 1
  }
}

htd__update()
{
  for CK in ck sha1 md5
  do
    htd__ck_prune $CK
    htd__ck_clean $CK
    htd__ck_update $CK
  done
}


# Checksums

ck_arg_spec="[ck|sha1|md5]"
ck_arg()
{
  test -n "$1"  && CK=$1  || CK=ck
  test -e table.$CK || {
    error "First argument must be CK table extension, no such table: table.$CK" 1
  }
  test -r table.$CK || {
    error "Not readable: table.$CK" 1
  }
  T_CK="$(echo $CK | tr 'a-z' 'A-Z')"
}

ck_write()
{
  ck_arg "$1"
  test -w table.$CK || {
    error "Not writable: table.$CK" 1
  }
}

htd__man_5_table_ck="Table of CK checksum, filesize and path"
htd__man_5_table_sha1="Table of SHA1 checksum and path"
htd__man_5_table_md5="Table of MD5 checksum and path"
# Either check table for path, or iterate all entries. Echoes checksum, two spaces and a path
htd__ck_table()
{
  # table ext
  ck_arg "$1"
  shift 1
  # second table ext
  test -n "$1" -a -e "table.$CK.$1" && {
    S=$1; shift 1
  } || S=
  test -z "$1" && {
    # run all entries
    cat table.$CK$S | grep -Ev '^\s*(#.*|\s*)$' | \
    while read -a ckline
    do
      test "$CK" = "ck" && {
        cks=${ckline[@]::1}
        sz=${ckline[@]::1}
        p="${ckline[@]:2}"
      } || {
        cks=${ckline[@]::1}
        p="${ckline[@]:1}"
      }
      echo "$cks  $p"
    done
  } || {
    # look for single path
    htd_relative_path "$1"
    match_grep_pattern_test "$relpath" || return 1
    grep ".*\ \(\.\/\)\?$p_$" table.$CK$S >> /dev/null && {
      grep ".*\ \(\.\/\)\?$p_$" table.$CK$S | cut -f 1 -d ' '
    } || {
      echo unknown
      return 1
    }
  }
}

htd_man_1__ck_table_subtree="Like ck-table, but this takes a partial path starting at the root level and returns the checksum records for files below that. "
htd__spc_ck_table_subtree="ck-tabke-subtree $ck_arg_spec <path>"
htd__ck_table_subtree()
{
  ck_arg "$1"
  shift 1
  test -n "$1" || return 1
  match_grep_pattern_test "$1" || return 1
  grep ".*\ $p_.*$" table.$CK | grep -v '^\(\s*\|#.*\)$' | \
  while read -a ckline
    do
      test "$CK" = "ck" && {
        cks=${ckline[@]::1}
        sz=${ckline[@]::1}
        p="${ckline[@]:2}"
      } || {
        cks=${ckline[@]::1}
        p="${ckline[@]:1}"
      }
      echo "$cks  $p"
    done
}

ck_update_file()
{
  ck_write "$CK"
  update_file="$1"
  # FIXME use test name again but must have some testcases
  # to verify because currently htd_name_precaution is a bit too strict
  # htd__test_name
  match_grep_pattern_test "$update_file" > /dev/null || {
    error "Skip path with unhandled characters"
    return
  }
  test -r "$update_file" || {
    error "Skip path not readable by user"
    return
  }
  test -d "$update_file" && {
    error "Skipped directory path"
    return
  }
  test -L "$update_file" && {
    BE="$(dirname "$update_file")/$(readlink "$update_file")"
    test -e "$BE" || {
      error "Skip dead symlink"
      return
    }
    SZ="$(filesize "$BE")"
  } || {
    SZ="$(filesize "$update_file")"
  }
  test "$SZ" -ge "$MIN_SIZE" || {
    error "File too small: $SZ"
    return
  }
  # test localname for SHA1 tag
  BN="$(basename "$update_file")"
  # XXX hardcoded to 40-char hexsums ie. sha1
  HAS_CKS="$(echo "$BN" | grep '\b[0-9a-f]\{40\}\b')"
  cks="$(echo "$BN" | grep '\b[0-9a-f]\{40\}\b' |
    sed 's/^.*\([0-9a-f]\{40\}\).*$/\1/g')"
  # FIXME: normalize relpath
  test "${update_file:0:2}" = "./" && update_file="${update_file:2}"
  #EXT="$(echo $BE)"
  test -n "$HAS_CKS" && {
    htd__ck_table "$CK" "$update_file" > /dev/null && {
      echo "path found"
    } || {
      grep "$cks" table.$CK > /dev/null && {
        echo "$CK duplicate found or cannot grep path"
        return
      }
      CKS=$(${CK}sum "$update_file" | cut -d' ' -f1)
      test "$cks" = "$CKS" || {
        error "${CK}sum $CKS does not match name $cks from $update_file"
        return
      }
      echo "$cks  $update_file" >> table.$CK
      echo "$cks added"
      return
    }
    return
  } || {
    # TODO prepare to rename, keep SHA1 hashtable
    htd__ck_table "$CK" "$update_file" > /dev/null && {
      echo ok
    } || {
      ${CK}sum "$update_file" >> table.$CK
      echo new
    }
  }
}

ck_update_find()
{
  log "Reading $T_CK, looking for paths '$1'"
  find_p="$1"
  # strip trailing slash
  test "${find_p: -1:1}" = "/" && find_p="${find_p:0: -1}"
  eval find "$find_p" $find_ignores -o -print \
  | while read p
    do
      ck_update_file "$p"
    done
}

# find all files, check their names, size and checksum
htd__ck_update()
{
  ck_write "$1"
  shift 1
  #args=($@);
  while test -e "$1"
  do
    update_p="$1"
    shift 1
    log "Checking '$update_p'"
    test -z "$update_p"  && {
      ck_update_find . 
      continue
    }
    test -d "$update_p"  && {
      ck_update_find "$update_p"
      continue
    }
    test -f "$1" && {
      ck_update_file "$1"
      continue
        }
    test -L "$1"  &&  {
      ck_update_file "$1" || return 4
      continue
    }
    shift 1
  done
  test -z "$1" || error "Unknown path '$1'" 1
}

htd__ck_drop()
{
  ck_write "$1"
  shift 1
  ck_drop "$1"
  req_arg "$1" 'ck-drop' 2 path || return 1
  match_grep_pattern_test "$1" || return 1
  cp table.$CK table.$CK.tmp
  cat table.$CK.tmp | grep "^.*$p_$" >> table.$CK.missing
  cat table.$CK.tmp | grep -v "^.*$p_$" > table.$CK
  rm table.$CK.tmp
}

htd_man_1__ck_clean="Iterate checksum table, check for duplicates, normalize paths"
htd__spc_ck_clean="clean $ck_arg_spec"
htd__ck_clean()
{
  ck_arg "$1"
  shift 1
  test "$CK" = "ck" && {
    set --
  } || {
    set --
  }
}

htd__spc_ck_validate="ck-validate $ck_arg_spec"
htd__ck_validate()
{
  ck_arg "$1"
  shift 1
  test "$CK" = "ck" && {
    htd__checksums table.$CK
  } || {
    ${CK}sum -c table.$CK
  }
}

# check file size and cksum
htd__spc_checksums="checksums [<table-file>]"
htd__checksums()
{
  test -n "$1"  && T=$1  || T=table.ck
  cat $T | while read cks sz p
  do
    SZ="$(filesize "$p")"
    test "$SZ" = "$sz" || { error "File-size mismatch on '$p'"; continue; }
    CKS="$(cksum "$p" | awk '{print $1}')"
    test "$CKS" = "$cks" || { error "Checksum mismatch on '$p'"; continue; }
    echo "$cks ok"
  done
}

# Drop non-existant paths from table, copy to .missing
htd__ck_prune()
{
  ck_write "$1"
  shift 1
  log "Pruning missing files from $CK table"
  htd__ck_table $CK | while read cks p
  do
    test -e "$p" || {
      htd__ck_drop $CK "$p"
      echo "Dropped $CK key $cks for '$p'"
    }
  done
}

# Read checksums from *.{sha1,md5,ck}{,sum}
htd__ck_consolidate()
{
  eval "find . $find_ignores -o -name '*.{sha1,md5,ck}{,sum}' -a \( -type f -o -type l \) " -print | while read p
  do
    echo "$p"
  done
}

# try to find files from .missing, or put them in .gone
htd__ck_clean()
{
  ck_write "$1"
  shift 1
  test -s "table.$CK.missing" || {
    error "$T_CK.missing table does not exists"
    return
  }
  log "Looking for missing files from $CK table"/
  htd__ck_table $CK .missing | while read cks p
  do
    BN="$(basename "$p")"
    NW=$(eval find ./ $find_ignores -o -iname '$BN' -print)
    test -n "$NW" && echo "$BN -> $NW"
  done
  echo 'TODO rewrite ck table path'
}

# TODO consolidate meta
htd__ck_metafile()
{
  [ -n "$1" ] && d=$1 || d=.
  CK=sha1
  eval find $d $find_ignores -o -iname \'*.meta\' -print \
  | while read metafile
  do
    ck_mf_p="$(dirname "$metafile")/$(basename "$metafile" .meta)"
    [ -e "$ck_mf_p" ] || {
      echo "missing source file $metafile: $ck_mf_p"
      continue
    }
    cks=$(rsr.py --show-sha1sum-hexdigest "$ck_mf_p" 2> /dev/null)
    htd__ck_table "$CK" "$ck_mf_p" > /dev/null && {
      log "$cks found"
    } || {
      CKS=$(${CK}sum "$ck_mf_p" | cut -d' ' -f1)
      #echo CKS=$CKS cks=$cks
      test "$cks" = "$CKS" && {
        log "$CKS ok $ck_mf_p"
      } || {
        error "Corrupt file: $ck_mf_p"
        continue
      }
      echo "$CKS  $ck_mf_p" >> table.$CK
    }
    
  done
}

# validate torrent
htd__ck_torrent()
{
  test -s "$1" || error "Not existent torrent arg 1: $1" 1
  test -f "$1" || error "Not a torrent file arg 1: $1" 1
  test -z "$2" -o -d "$2" || error "Missing dir arg" 1
  htwd=$(pwd)
  dir=$2
  test "$dir" != "." && pushd $2 > /dev/null
  test "${dir: -1:1}" = "/" && dir="${dir:0: -1}"
  log "In $dir, verify $1"

  #echo testing btshowmetainfo
  #btshowmetainfo $1

  node $PREFIX/bin/btinfo.js "$1" > /tmp/htd-ck-torrent.sh
  . /tmp/htd-ck-torrent.sh
  echo BTIH:$infoHash

  torrent-verify.py "$1" | while read line
  do
    test -e "${line}" && {
      echo $htwd/$dir/${line} ok
    }
  done
  test "$dir" != "." && popd > /dev/null
}


# xxx find corrupt files: .mp3
htd__mp3_validate()
{
  eval "find . $find_ignores -o -name "*.mp3" -a \( -type f -o -type l \) -print" \
  | while read p
  do
    SZ=$(filesize "$p")
    test -s "$p" || {
      error "Empty file $p"
      continue
    }
    mp3val "$p"
  done
}

htd__mux()
{
  test -n "$1" || set -- "docker-"
  test -n "$2" || set -- "$1" "dev"
  test -n "$3" || set -- "$1" "$2" "$(hostname -s)"

  note "tmuxinator start $1 $2 $3"
  tmuxinator start $1 $2 $3
}

htd__tmux_prive()
{
  test -n "$1" || set -- "*"
  cd
  case "$1" in init|"*" )
  tmux has-session -t Prive >/dev/null || {
    htd__tmux_init Prive
    tmux send-keys -t Prive:1 "cd;simza test" enter
  }
  tmux list-windows -t Prive | grep -q HtD || {
    tmux new-window -t Prive -n HtD
    tmux send-keys -t Prive:HtD "cd ~/htdocs/; htd today personal/journal;git st" enter
    tmux send-keys -t Prive:HtD "git add -u;git add dev/ personal/*.rst personal/journal/2*.rst sysadmin/*.rst *.rst;git st" enter
    note "Initialized 'HtD' window"
  }
  tmux list-windows -t Prive | grep -q '\ conf' || {
    tmux new-window -t Prive -n conf
    tmux send-keys -t Prive:conf "cd ~/.conf;git st" enter
    note "Initialized 'conf' window"
  }
  tmux list-windows -t Prive | grep -q Bin || {
    tmux new-window -t Prive -n Bin
    tmux send-keys -t Prive:Bin "cd ~/bin;git st" enter
    note "Initialized 'Bin' window"
  }
  ;; esac

  case "$1" in ino|"*" )
  tmux list-windows -t Prive | grep -q Ino || {
    tmux new-window -t Prive -n Ino
    tmux send-keys -t Prive:Ino "cd ~/project/arduino-docs;git st" enter
    note "Initialized 'Ino' window"
  }
  ;; esac
  case "$1" in eagle|"*" )
  tmux list-windows -t Prive | grep -q EAGLE || {
    tmux new-window -t Prive -n EAGLE
    tmux send-keys -t Prive:EAGLE "cd ~/project/Eagle-mpe;git st" enter
    note "Initialized 'EAGLE' window"
  }
  ;; esac
  #tmux list-windows -t Prive | grep -q Loci || {
  #  tmux new-window -t Prive -n Loci
  #  tmux send-keys -t Prive:Loci "cd ~/project/node-loci;git st" enter
  #}
  case "$1" in sf|"*" )
  tmux list-windows -t Prive | grep -q Sf || {
    tmux new-window -t Prive -n Sf
    tmux send-keys -t Prive:Sf "cd ~/project/node-sitefile;git st" enter
    note "Initialized SiteFile [Sf] window"
  }
  ;; esac
  case "$1" in docs|"*" )
  tmux list-windows -t Prive | grep -q Docs || {
    tmux new-window -t Prive -n Docs
    tmux send-keys -t Prive:Docs "cd ~/Documents/;git st" enter
    note "Initialized Documents window"
  }
  ;; esac
}

htd__tmux_work()
{
  test -n "$1" || set -- "*"
  cd ~/work/brix

  ### Make sure Work session is registered with tmux server

  case "$1" in init|"*" )

  tmux has-session -t Work >/dev/null || htd__tmux_init Work bash
  sleep 2

  # Make sure Log window is on and first window (swapping some windows if
  # needed, maybe better way it to start server by hand instead of usign new-session?)

  tmux list-windows -t Work | grep -q Log || {
    # No log, new session, need to clean up first window, add one first to keep session
    tmux new-window -t Work -n temporary
    tmux kill-window -t Work:1
  }
  sleep 1

  tmux list-windows -t Work | grep -q '1:\ Log' || {
    tmux new-window -t Work -n Log
    tmux send-keys -t Work:Log "cd ~/work/brix/;htd today log" enter
    tmux send-keys -t Work:Log "(cd log;git add -u;git add 20*.rst; git st)" enter
  }
  sleep 1

  tmux list-windows -t Work | grep -q temporary && {
    tmux kill-window -t Work:temporary
  } || noop

  ;; esac


  ### Add other windows

  case "$1" in tree|"*" )
  tmux list-windows -t Work | grep -q Tree || {
    tmux new-window -t Work -n Tree
    tmux send-keys -t Work:Tree "cd ~/work/brix/" enter "make status" enter
    note "Initialized Tree window"
  }
  ;; esac
  case "$1" in cln|"*" )
  tmux list-windows -t Work | grep -q Cleaning || {
    tmux new-window -t Work -n TreeCln
    tmux send-keys -t Work:TreeCln "cd /Volumes/Simza/WorkCleaning/brix" enter "make status" enter
    note "Initialized TreeCln window"
  }
  ;; esac
  case "$1" in jenkins )
      htd tmux-winit Work Jnk ~/work/brix/Jenkins \
        "(cd jenkins-ci-config && git fetch --all && git status); (cd userContent && git fetch --all && git status)"
  ;; esac
  case "$1" in dev-doc )
      htd tmux-winit Work DvD ~/work/brix/tree/dev-doc
  ;; esac
  case "$1" in skel* )
      htd tmux-winit Work Skl ~/work/brix/tree/project-skeleton-ng
  ;; esac
  case "$1" in mango|"*" )
      htd tmux-winit Work MngB /Volumes/Simza/WorkCleaning/brix/tree/mango-builds
  ;; esac

  case "$1" in studio|"*" )
  tmux list-windows -t Work | grep -q BrxStd || {
    tmux new-window -t Work -n BrxStd
    tmux send-keys -t Work:BrxStd "cd /Volumes/Simza/WorkCleaning/brix/tree/brixcloud-studio-testing" enter "git st" enter
    note "Initialized BrxStd window"
  }
  tmux list-windows -t Work | grep -q BrxStdT || {
    tmux new-window -t Work -n BrxStdT
    tmux send-keys -t Work:BrxStdT "cd /Volumes/Simza/WorkCleaning/brix/tree/brixcloud-studio-testing2;ls -la" enter
    note "Initialized BrxStdT window"
  }
  tmux list-windows -t Work | grep -q BrxStdSkl || {
    tmux new-window -t Work -n BrxStdSkl
    tmux send-keys -t Work:BrxStdSkl "cd ~/work/brix/tree/brixcloud-studio-skeleton" enter "git st" enter
    note "Initialized BrxStdSkl window"
  }
  ;; esac


  ### Clients

  case "$1" in sw|stein*|steinweg )
  tmux list-windows -t Work | grep -q Sw || {
    tmux new-window -t Work -n Sw
    # TODO
    tmux send-keys -t Work:Sw "cd /Volumes/Simza/work/brix/tree/steinweg" enter "git st" enter
    note "Initialized Sw window"
  }
  ;; esac
}

htd__tmux_srv()
{
  cd /srv
  tmux has-session -t Srv >/dev/null || {
    htd__tmux_init Srv
    tmux send-keys -t Srv:bash "cd ~/.conf; ./script/update.sh" enter
  }
  tmux list-windows -t Srv | grep -q HtD-Sf || {
    tmux new-window -t Srv -n HtD-Sf
    tmux send-keys -t Srv:HtD-Sf "cd ~/htdocs/; sitefile" enter
  }
  tmux list-windows -t Srv | grep -q BrX-Sf || {
    tmux new-window -t Srv -n BrX-Sf
    tmux send-keys -t Srv:BrX-Sf "cd ~/work/brix/; sitefile" enter
  }
  tmux list-windows -t Srv | grep -q X-Tw || {
    tmux new-window -t Srv -n X-Tw
    tmux send-keys -t Srv:X-Tw "cd ~/project/x-tiddlywiki; tiddlywiki x-tiddlywiki --server" enter
  }
  tmux list-windows -t Srv | grep -q Loci || {
    tmux new-window -t Srv -n Loci
    tmux send-keys -t Srv:Loci "cd ~/project/node-loci; npm start" enter
  }
}


# htd tmux-winit SESSION WINDOW DIR CMD
htd__tmux_winit()
{
  ## Parse args
  test -n "$1" || error "Session <arg1> required" 1
  test -n "$2" || error "Window <arg2> required" 1
  test -n "$3" || {
    # set working dir
    case "$1" in
      Work )
        set -- "$1" "$2" "~/work/brix/tree/$2" ;;
      Prive )
        set -- "$1" "$2" "~/project/$2" ;;
      * ) 
        error "Cannot setup working-dir for window '$1:$2'" 1 ;;
    esac
  }
  test -d "$3" || error "Expected <arg3> to be directory '$3'" 1
  test -n "$4" || {
    set -- "$1" "$2" "$3" "git fetch --all && status" 
  }

  tmux list-windows -t $1 | grep -q $2 && {
    note "Window '$1:$2' already initialized"
  } || {
    tmux new-window -t $1 -n $2
    tmux send-keys -t $1:$2 "cd $3" enter "$4" enter
    note "Initialized '$1:$2' window"
  }
}

htd__tmux_init()
{
  test -n "$1" || error "session name required" 1
  test -n "$2" || set -- "$1" "bash"
  #'reattach-to-user-namespace -l /bin/bash'"
  test -z "$3" || error "surplus arguments: '$3'" 1

  socket=/tmp/tmux-htd-socket
  out=/tmp/htd-tmux-init-$$

  test -n "$TMUX_TMPDIR" || TMUX_TMPDIR=/opt/tmux-socket

  tmux has-session -t $1 >/dev/null && {
    logger "Session $1 exists" 0
    note "Session $1 exists" 0
  } || {

    tmux new-session -P -s "$1" -d "$2" 2>$out 1> $out

    tmux has-session -t "$1" >/dev/null || {
      log "Waiting for tmux session";
      sleep 5;
    }

    tmux has-session -t $1 >/dev/null && {
      note "started new session '$1'"
      logger "started new session '$1'"
    } || {
      logger "Failed starting session ($?) ($out):"
      printf "Cat ($out) "
    }

    rm $out
  }

  # Look for init subcmd to setup windows
  try_exec_func "htd__tmux_$(echo $1 | tr 'A-Z' 'a-z')" || noop
  # XXX: or try tmuxinator
}

htd__reader_update()
{
  cd /Volumes/READER

  for remote in .git/refs/remotes/*
  do
    name="$(basename "$remote")"
    younger_than "$remote" _1HOUR && {
      info "Remote $name is up-to-date"
    } || {
      note "Remote $name is too old, syncing"
      git annex sync $name && continue || error "sync failed"
    }
  done

  note "Removing dead symlinks (annex content elsewhere), for PRS software"
  find ./ -type l | while read l
  do
      test -e "$l" || rm "$l"
  done
}

htd_man_1__test="no test, just checking it goes"
htd__test()
{
  ./test/*-spec.bats
}
htd_als___t=test


htd_man_1__edit_test="edit-tests"
htd__edit_test()
{
  $EDITOR ./test/*-spec.bats
}
htd_als___T=edit-test


htd_man_1__inventory="All inventories"
htd__inventory()
{
  $EDITOR personal/inventory/{main,*}.rst
  git add personal/inventory/{main,*}.rst
}

htd_man_1__inv_elec="Electrics inventory"
htd__inv_elec()
{
  $EDITOR personal/inventory/{components,modules,hardware}.rst
  git add personal/inventory/{components,modules,hardware}.rst
}

htd__disk_id()
{
  test -n "$1" || error "Disk expected" 1
  test -e "$1" || error "Disk path expected '$1'" 1

  diskid="$(sudo fdisk -l $1 | grep Disk.identifier\
      | sed 's/^Disk.identifier: //')"
  echo $diskid
}

htd__disk_model()
{
  test -n "$1" || error "Disk expected" 1
  test -e "$1" || error "Disk path expected '$1'" 1

  diskmodel="$(sudo parted -s $1 print | grep Model: \
      | sed 's/^Model: //')"
  echo $diskmodel
}

htd__disk_size()
{
  test -n "$1" || error "Disk expected" 1
  test -e "$1" || error "Disk path expected '$1'" 1

  disksize="$(sudo parted -s $1 print | grep Disk.*: \
      | sed 's/^Disk[^:]*: //')"
  echo $disksize
}

htd__disk_tabletype()
{
  test -n "$1" || error "Disk expected" 1
  test -e "$1" || error "Disk path expected '$1'" 1

  disktabletype="$(sudo parted -s $1 print | grep Partition.Table: \
      | sed 's/^Partition.Table: //')"
  echo $disktabletype
}

find_partition_ids()
{
  find /dev/disk/by-uuid -type l | while read path
  do
    test "$(basename $(readlink $path))" != "$(basename $1)" || {
      echo UUID:$(basename $path)
    }
  done

  if test -e /dev/disk/by-partuuid
  then
    find /dev/disk/by-partuuid -type l | while read path
    do
      test "$(basename $(readlink $path))" != "$(basename $1)" || {
        echo PART-UUID:$(basename $path)
      }
    done
  fi
}

htd__disks()
{
  test -n "$rst2xml" || error "rst2xml required" 1
  sudo which parted 1>/dev/null && parted=$(sudo which parted) \
    || warn "No parted"
  test -n "$parted" || error "parted required" 1
  DISKS=/dev/sd[a-e]
  for disk in $DISKS
  do
    echo "$disk $(htd disk-id $disk)"
    echo "  :table-type: $(htd disk-tabletype $disk)"
    echo "  :size: $(htd disk-size $disk)"
    echo "  :model: $(htd disk-model $disk)"
    echo ""
    for dp in $disk[0-9]*
    do
        pn="$(echo $dp | sed 's/^.*\([0-9]*\)/\1/')"
        ps="$(sudo parted $disk -s print | grep '^\ '$pn | awk '{print $4}')"
        pt="$(sudo parted $disk -s print | grep '^\ '$pn | awk '{print $5}')"
        fs="$(sudo parted $disk -s print | grep '^\ '$pn | awk '{print $6}')"
        echo "  - $dp $pt $(echo $(find_partition_ids $dp)) $ps $fs"
    done
    echo
  done
  echo
}


htd__realpath()
{
  realpath "$@"
}

htd__normalize_symbolic()
{
  normalize_symbolic "$@"
}

htd__normalize_relative()
{
  normalize_relative "$1"
}

# Get document part using xpath
# XXX: relies on rST/XML.
htd__getx()
{
  test -n "$1" || error "Document expected" 1
  test -e "$1" || error "No such document <$1>" 1
  test -n "$2" || error "XPath expr expected" 1

  test -n "$3" || set "$1" "$2" "$(htd__getxl $1)"

  xmllint --xpath "$2" "$3"
}

# Get x-lang file for arg1
htd__getxl()
{
  fnmatch '*.xml' $1 && set -- "$1" "$1"
  fnmatch '*.rst' $1 && {
    test -n "$2" || set -- "$1" "/tmp/$(basename $1 .rst).xml"
    $rst2xml $1 > "$2"
    echo $2
  }
  test -e "$2" || error "Need XML repr of doc $1" 1
}

# List topic paths (nested dl terms) in document paths
htd__tpaths()
{
  test -n "$1" || error "At least one document expected" 1
  test -n "$print_src" || local print_src=

  while test -n "$1"
  do
    test -e "$1" || {
      warn "No file <$1>, skipped"
      shift 1
      continue
    }
    path= rel_leaf= root=

    # Read multi-leaf paths, and split it up into relative leafs
    htd__xproc "$(htd__getxl $1)" $scriptdir/rst-terms2path.xsl \
      | grep -Ev '^(#.*|\s*)$' \
      | sed 's/\([^\.]\)\/\.\./\1\
../g' \
      | grep -v '^\.[\.\/]*$' \
      | while read rel_leaf
    do

      # Assemble each leaf path onto its root, and normalize
      echo "$rel_leaf" | grep -q '^\.\.\/' && {
        path="$(normalize_relative "$path/$rel_leaf")"
      } || {
        path="$(normalize_relative "$rel_leaf")"
      }

      test -n "$print_src" \
        && echo "$1 $path" \
        || echo "$path"

    done

    unset path rel_leaf root
    shift 1
  done
}

htd__tpath_raw()
{
  test -n "$1" || error "document expected" 1
  test -e "$1" || error "no such document '$1'" 1
  htd__xproc "$(htd__getxl "$1")" $scriptdir/rst-terms2path.xsl
}

# Process XML using XSLT
htd__xproc()
{
  {
    fnmatch '<* *>' "$2" && {

      xsltproc --novalid - $1 <<EOM
$2
EOM
    } || {
      xsltproc --novalid $2 $1
    }
  # remove XML prolog:
  } | tail -n +2 | grep -Ev '^(#.*|\s*)$'
}

# TODO: Append definition term to doc
htd__dl_init()
{
  test -n "$1" || error "Document expected" 1
  test -e "$1" || error "Document expected: <$1>" 1
  test -n "$2" || error "Term expected" 1
  htd getx '//*/term[text()="'$2'"]' "$1"
}

# TODO: Add list item beneath definition term
htd__dl_append()
{
  echo
}

# XXX: hacky hacking one day, see wishlist above
list_host_disks()
{
  htd getx sysadmin/$hostname.rst \
    "//*/term[text()='Disk']/ancestor::definition_list_item/definition/definition_list" \
    > /tmp/$hostname-disks.xml
  {
    xsltproc - /tmp/$hostname-disks.xml <<EOM
<xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform">
<xsl:template match="definition_list_item">
<xsl:value-of select="term"/> .
</xsl:template>
</xsl:stylesheet>
EOM
  # remove XML prolog:
  } | tail -n +2 | grep -Ev '^(#.*|\s*)$'
}

htd__check_disks()
{
  test -d $HTDIR || error "No HTDIR" 1
  cd $HTDIR
  list_host_disks | while read label path id eol
  do
    test -e "$path" && {
      echo "Path for $label OK"
      xmllint --xpath \
          "//definition_list/definition_list_item/definition/bullet_list/list_item[contains(paragraph,'"$path"')]/ancestor::bullet_list" \
          /tmp/$hostname-disks.xml > /tmp/$hostname-disk.xml;
      {
    xsltproc - /tmp/$hostname-disk.xml <<EOM
<xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform">
<xsl:template match="//bullet_list/list_item">
<xsl:value-of select="paragraph/text()"/> .
</xsl:template>
</xsl:stylesheet>
EOM
  # remove XML prolog:
  } | tail -n +2 | grep -Ev '^(#.*|\s*)$' \
      && {
        echo
      } || {
        warn "failed $?"
      }

    } || {
      error "Missing $label $id <$path>" 1
    }
  done
}


# Setup X tcp socket for VS1 containers
htd__xtcp()
{
  socat TCP-LISTEN:6000,reuseaddr,fork UNIX-CLIENT:\"$DISPLAY\"
}


gcal_tab=~/.conf/google/cals.tab
htd__man_5_cals_tab="List of Google calendar IDs"

gcal_tab_ids()
{
  if test -n "$1"
  then
    cat $gcal_tab
  else
    grep '\<'$1 $gcal_tab
  fi
}

# List current and upcoming events
htd__events()
{
  test -n "$2" || set -- "$1" "days=3"

  cat ~/.conf/google/cals.tab | while read calId summary
  do
    note "Upcoming events for '$summary'"
    gcal.py list-upcoming 7 $calId "$2" 2>/dev/null
  done
}

# List upcoming events at any date
htd__upcoming_events()
{
  gcal_tab_ids "$1" | while read calId summary
  do
    note "Upcoming events for '$summary'"
    gcal.py list-upcoming 7 $calId 2>/dev/null
  done
}

# List events of +/- 1day
htd__current_events()
{
  test -n "$2" || set -- "$1" "days=1" "$3" "$4"
  test -n "$3" || set -- "$1" "$2" "days=1" "$4"
  test -n "$4" || set -- "$1" "$2" "$3" "7"

  gcal_tab_ids "$1" | while read calId summary
    do
      note "Current events ($2/$3) for '$summary' ($calId)"
      gcal.py happening-now $7 $calId "$1" "$2" 2>/dev/null
    done
}


htd__active()
{
  test -n "$tdata_fmt" && {
    note "Listing files active in '$@'"
  } || {
    tdata_fmt=$TODAY
    note "Listing files active today in '$@'"
  }
  tdate=$(date "$1")

  test -n "$2" || set -- "$1" "$(pwd -P)"
  shift
  test -n "$tdate" || error "formatting date" 1
  touch -t $tdate $(statusdir.sh file recent-paths)
  htd__recent_paths "$@"
}


# List open paths under given or current dir. Dumps lsof without cmd, pid etc.
htd__current_paths()
{
  test -n "$1" || set -- "$(pwd -P)"
  note "Listing open paths under $1"
  # print only pid and path name, keep name
  lsof -Fn +D $1 | tail -n +2 | grep -v '^p' | cut -c2- | sort -u
}
htd_als__lsof=current-paths

# List paths newer than recent-paths setting
htd__recent_paths()
{
  test -n "$1" || set -- "$(pwd -P)"
  note "Listing active paths under $1"
  dateref=$(statusdir.sh file recent-paths)
  find $1 -newer $dateref
}


# Scan for bashims in given file or current dir
htd__bashisms()
{
  test -n "$1" || set -- "."
  f=-srI

  # Scan for bash redirect
  grep $f '\&>' "$@" && {
    note "Bash extension found: '&>...' is a shortcut for '>... 2>&1'"
  }

  # Scan for bash, ksh etc. keyword
  grep $f '\<source\|declare\|typeset\>' "$@" && {
    note "Bash extension found"
  }
}


htd_man_1__clean_unpacked="Given archive, look for existing, possibly unpacked (direct) neighbour dirs
interactively delete, compare, or skip"
htd__clean_unpacked()
{
  test -n "$1" || error "archive" 1
  test -n "$2" || set -- "$1" "$(dirname "$1")"

  test -e "$1" && {
    test -f "$1" || error "not a file: '$1'" 1
  } || {
    test -h "$1" && {
      warn "skipped broken symlink '$1'"
      return 1
    } || error "No archive '$1'" 2
  }

  local  archive="$(basename "$1")"

  set -- "$(cd "$(dirname "$1")"; pwd -P)/$archive" "$2"

  local oldwd="$(pwd)" dirty="$(statusdir.sh file htd clean-unpacked)"
  test ! -e "$dirty" || rm "$dirty"

  cd "$2"

  # scenario 1: look for archive-basename as dir (ie. unzip, some friendlier unpackers--Darwin, Gnome maybe)
  local dir="$(archive_basename "$1")"
  test -d "$dir" && {

    archive_update "$1" && {
      test -z "$dry_run" && {
        error "rm -rf $dir"
      } || {
        note "looking clean $1 (** DRY-RUN **) "
      }
    } || {
      note "Possibly unpacked basedir '$dir' (from $1)"
      touch $dirty
    }

  } || {

    # scenario 2: look root dirs from archive
    archive_list "$1" crc32 name | sed 's/^\([^\/]*\).*$/\1/' | sort -u | while read path
    do
      test -e "$path" && {
        note "Possibly unpacked path '$path' (from $1)"
        touch $dirty
      } || {
        debug "No dir $(pwd)/$path"
        continue
      }
    done

  }

  cd "$oldwd"

  test ! -e "$dirty" && stderr ok "$1" || warn "Crufty $1" 1
}

# given archive, note unpacked files
htd__note_unpacked()
{
  test -n "$1" || error "archive" 1
  test -n "$2" || set -- "$1" "$(dirname "$1")"

  test -e "$1" && {
    test -f "$1" || error "not a file: '$1'" 1
  } || {
    test -h "$1" && {
      warn "skipped broken symlink '$1'"
      return 1
    } || error "No archive '$1'" 2
  }

  local  archive="$(basename "$1")"

  set -- "$(cd "$(dirname "$1")"; pwd -P)/$archive" "$2"

  local oldwd="$(pwd)" dirty="$(statusdir.sh file htd note-unpacked)"
  test ! -e "$dirty" || rm "$dirty"

  cd "$2"

  archive_list "$1" | while read file
  do
    test -e "$file" && {
      note "Found unpacked $file (from $archive)"
      touch $dirty
      # check for changes?
    } || {
      debug "No file $(pwd)/$file"
      continue
    }
  done

  cd "$oldwd"

  test ! -e "$dirty" && info "OK $1" || warn "Crufty $1" 1
}

# given archive, note files out of sync
htd__test_unpacked()
{
  test -n "$1" || error "archive" 1
  test -n "$2" || set -- "$1" "$(dirname "$1")"

  test -e "$1" && {
    test -f "$1" || error "not a file: '$1'" 1
  } || {
    test -h "$1" && {
      warn "skipped broken symlink '$1'"
      return 1
    } || error "No archive '$1'" 2
  }

  local  archive="$(basename "$1")"

  set -- "$(cd "$(dirname "$1")"; pwd -P)/$archive" "$2"

  local oldwd="$(pwd)" dirty=
  #"$(statusdir.sh file htd test-unpacked)"
  #test ! -e "$dirty" || rm "$dirty"

  cd "$2"

  archive_update "$1" || dirty=1

  cd $oldwd

  test -z "$dirty" && info "OK $1" || warn "Crufty $1" 1
}

archive_basename()
{
  test -n "$1" || error "archive-basename:1" 1
  case "$1" in
    *.zip )
      basename "$1" .zip
      ;;
    * )
      error "archive-basename ext: '$1'" 1
  esac
}

archive_list()
{
  test -n "$1" || error "archive-list:1" 1
  case "$1" in
    *.zip )
      unzip -l "$1" | read_unzip_list
      ;;
    * )
      error "archive-list ext: '$1'" 1
  esac
}

read_unzip_list()
{
  oldIFS=$IFS
  IFS=\n
  read
  read headers
  # see fixed_table_hd_offset; dont bother with 0-index correction here
  # XXX: expr still helps to strip ws even with IFS off..? [Darwin]
  offset=$(( $(printf "$headers" | sed 's/^\(.*\)'Name'.*/\1/g' | wc -c) - 0 ))
  read
  while read line
  do
    case $line in " "*---- | " "*[0-9]*" files" ) continue ;; esac
    #printf "line='$line'\n"
    printf -- "%s" "$line" | cut -c$offset-
  done
  IFS=$oldIFS
}

# TODO: update/list files out of sync
# XXX: best way seems to use CRC (from -lv output at Darwin)
archive_update()
{
  test -n "$1" || error "archive-update:1" 1
  local dirty="$(statusdir.sh file htd archive-update dirty)" \
    cnt="$(statusdir.sh file htd archive-update count)"
  test ! -e "$dirty" || rm "$dirty"
  printf 0 >$cnt
  case "$1" in
    *.zip )
      unzip -lv "$1" | read_unzip_verbose_list | while read line
      do
        length="$(echo $line | cut -d\  -f 1)"
        crc32="$(echo  $line | cut -d\  -f 7)"
        name="$(echo   $line | cut -d\  -f 8)"
        debug "$name ($crc32, $length)"
        printf $(( $(cat "$cnt") + 1 )) > $cnt
        test -e "$name" && {
          test "$(filesize "$name")" = "$length" && {
            test "$(crc32 "$name")" = "$crc32" && {
              #stderr ok "$name ($1)"
              continue
            } || {
              warn "CRC-error $name ($1)" 1
              touch $dirty
            }
          } || {
            warn "Size mismatch $name ($1)" 1
            touch $dirty
          }
        }
      done
      ;;
    * )
      error "archive-list ect: '$1'" 1
  esac
  c=$(cat $cnt)
  test ! -e "$dirty" && stderr ok "$1 ($c files)" || warn "Dirty $1" 1
}

htd__archive_list()
{
  archive_verbose_list "$@"
}

# echo request fields
archive_verbose_list()
{
  test -n "$1" || error "archive-verbose-list:1" 1
  local f=$1
  shift 1
  test -n "$1" || error "archive-verbose-list:fields" 1
  fields="$(for x in "$@"; do printf "\$$x "; done)"
  case "$f" in

    *.zip )
        unzip -lv "$f" | read_unzip_verbose_list | while read line
        do
          length="$(echo $line | cut -d\  -f 1)"
          method="$(echo $line | cut -d\  -f 2)"
          size="$(echo $line   | cut -d\  -f 3)"
          ratio="$(echo $line  | cut -d\  -f 4)"
          date="$(echo  $line  | cut -d\  -f 5)"
          time="$(echo  $line  | cut -d\  -f 6)"
          crc32="$(echo  $line | cut -d\  -f 7)"
          name="$(echo   $line | cut -d\  -f 8)"
          eval echo $fields
        done
      ;;

    * )
      error "archive-list ect: '$1'" 1

  esac
}

read_unzip_verbose_list()
{
  oldIFS=$IFS
  IFS=\n
  read # 'Archive:'
  read hds # headers
  read cols # separator
  # Lines
  while read line
  do
    fnmatch *----* "$line" && break || noop
    printf -- "%s\n" "$line"
  done
  read cols # separator
  read # totals
  IFS=$oldIFS
}


htd__export_docker_env()
{
  launchctl setenv DOCKER_HOST $DOCKER_HOST
  launchctl setenv DOCKER_MACHINE_NAME $DOCKER_MACHINE_NAME
  launchctl setenv DOCKER_TLS_VERIFY $DOCKER_TLS_VERIFY
  launchctl setenv DOCKER_CERT_PATH $DOCKER_CERT_PATH
  note "OK"
}

htd__import_docker_env()
{
  echo DOCKER_HOST=$(launchctl getenv DOCKER_HOST)
  echo DOCKER_MACHINE_NAME=$(launchctl getenv DOCKER_MACHINE_NAME)
  echo DOCKER_TLS_VERIFY=$(launchctl getenv DOCKER_TLS_VERIFY)
  echo DOCKER_CERT_PATH=$(launchctl getenv DOCKER_CERT_PATH)
}


# Forced color output commands

htd__git_status()
{
  git -c color.status=always status
}

htd__ls()
{
  case "$uname" in
    Darwin )
      CLICOLOR_FORCE=1 ls $1
    ;;
    Linux )
      ls --colors=yes $1
    ;;
  esac
}


# XXX: to-html of vim-syntax highlited files. But what about ANSI in and out?
# Also, this does not seem to take colorscheme values?
# There is also ANSI HTML Adapter https://github.com/theZiz/aha
# Below is not ideal, maybe AHA is better.
#
# FIXME: pstree-color is perhaps not returning valid escapes, as 2html.vim chokes
htd__colorize()
{
  test -n "$1" || set -- "-"

  case "$1" in 
    
    - )

      set -- /tmp/htd-vim-colorize.out
      #{ cat - > $1 ; }
      #exec 0<&-

      #  -R -E -s  \
      vim \
        -c "syntax on" \
        -c "AnsiEsc" \
        -c "w! $1" \
        -c "let g:html_no_progress=1" \
        -c "let g:html_number_lines = 0" \
        -c "let g:html_use_css = 1" \
        -c "let g:use_xhtml = 1" \
        -c "let g:html_use_encoding = 'utf-8'" \
        -c "TOhtml" \
        -c "wqa!" \
        -

      open $1.xhtml

      rm /tmp/htd-vim-colorize* /tmp/.htd-vim-colorize*
      ;;

    * )
      test -e "$1" || error "no file $1" 1
      #  -E -s \
      # -R -E -s  \
      vim \
        -c "syntax on" \
        -c "AnsiEsc" \
        -c "let g:html_no_progress=1" \
        -c "let g:html_number_lines = 0" \
        -c "let g:html_use_css = 1" \
        -c "let g:use_xhtml = 1" \
        -c "let g:html_use_encoding = 'utf-8'" \
        -c "TOhtml" \
        -c "wqa!" \
        "$1"
      open $1.xhtml
      rm $1.xhtml
      ;;

  esac
}



htd__say()
{
  lang=$1
  shift
  test -n "$s" || s=f
  case "$lang" in
    uk )
      case "$s" in m )
          say -v Daniel "$@" ;;
        f ) 
          say -v Kate "$@" ;;
      esac;;
    us )
      case "$s" in m )
          say -v Alex "$@" ;;
        f ) 
          say -v Samantha "$@" ;;
      esac;;
    dutch | nl )
      case "$s" in m )
          say -v Xander "$@" ;;
        f ) 
          say -v Claire "$@" ;;
      esac;;
    japanese | jp )
      case "$s" in m )
          say -v Otoya "$@" ;;
        f )
          say -v Kyoko "$@" ;;
      esac;;
    chinese | cn | sc )
      say -v Ting-Ting "$@" ;;
    hong-kong | sar | tc )
      say -v Sin-ji "$@" ;;
  esac
}


### Main


htd_main()
{
  local scriptname=htd base=$(basename $htd_src .sh) verbosity=5

  case "$base" in $scriptname )

      htd_init || exit $?
      htd_lib || exit $?
      run_subcmd "$@" || exit $?
      ;;

    * )
      error "not a frontend for $base"
      ;;
  esac
}

htd_init()
{
  test -n "$LIB" || LIB=$HOME/bin
  . $LIB/std.lib.sh
  . $LIB/str.lib.sh
  . $LIB/os.lib.sh
  . $LIB/match.lib.sh
  . $LIB/util.sh
  . $LIB/box.init.sh
  box_run_sh_test
  . $LIB/htd.lib.sh
  . $LIB/main.sh
  . $LIB/main.init.sh
  . $LIB/box.lib.sh
  . $LIB/date.lib.sh
  . $LIB/doc.lib.sh
  . $LIB/table.lib.sh
  # -- htd box init sentinel --
}

htd_lib()
{
  local __load_lib=1
  . $LIB/match.sh load-ext
  # -- htd box lib sentinel --
  set --
}

# Use hyphen to ignore source exec in login shell
case "$0" in "" ) ;; "-"* ) ;; * )
  # Ignore 'load-ext' sub-command
  test -z "$__load_lib" || set -- "load-ext"
  case "$1" in load-ext ) ;; * )
    htd_main "$@"
  ;; esac
;; esac
